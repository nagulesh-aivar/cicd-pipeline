{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install boto3 pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFL9NWaGxdPL",
        "outputId": "3c7ab124-7482-4252-8ebd-9261cda25732"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import json\n",
        "import requests\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJitr6IL03XK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAVSIIP37VERPGV2KV\"\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = \"ap-south-1\"\n",
        "\n",
        "s3 = boto3.client(\"s3\")\n",
        "bucket_name = \"ginth-etl\"\n",
        "prefix = \"supply_note/purchase_order_data/source/\"\n",
        "processed = \"supply_note/purchase_order_data/processed/\"\n",
        "seeding_po_path = \"supply_note/purchase_order_data/seeding_data/purchase_order\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-bVnDpz027L",
        "outputId": "8f5893c9-9de0-426c-9239-a1139d65de9b"
      },
      "outputs": [],
      "source": [
        "objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
        "csv_files = [obj['Key'] for obj in objects.get('Contents', []) if obj['Key'].endswith('.csv')]\n",
        "print(f\"Found {len(csv_files)} CSV files.\")\n",
        "print(csv_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wipj04VG0_Go",
        "outputId": "381d04df-f155-4e74-c3cc-d93f82938919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined shape: (35320, 59)\n"
          ]
        }
      ],
      "source": [
        "all_data = []\n",
        "\n",
        "for key in csv_files:\n",
        "    print(\"Processing:\", key)\n",
        "    obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
        "    csv_str = obj[\"Body\"].read().decode(\"utf-8\").strip()\n",
        "\n",
        "    # 1Ô∏è‚É£ Skip files with \"NO DATA FOUND\" text or empty content\n",
        "    if not csv_str or \"NO DATA FOUND FOR THIS QUERY\" in csv_str.upper():\n",
        "        print(f\"‚ö†Ô∏è Skipping {key} ‚Äî no valid data found.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # 2Ô∏è‚É£ Try reading CSV safely\n",
        "        df = pd.read_csv(StringIO(csv_str))\n",
        "\n",
        "        # 3Ô∏è‚É£ Skip empty or header-only files\n",
        "        if df.empty or len(df.columns) == 0:\n",
        "            print(f\"‚ö†Ô∏è Skipping {key} ‚Äî empty or header-only file.\")\n",
        "            continue\n",
        "\n",
        "        # 4Ô∏è‚É£ Valid DataFrame ‚Üí append\n",
        "        all_data.append(df)\n",
        "        print(f\"‚úÖ Added {key} with shape {df.shape}\")\n",
        "\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"‚ö†Ô∏è Skipping {key} ‚Äî EmptyDataError.\")\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"‚ö†Ô∏è Skipping {key} ‚Äî ParserError: {e}\")\n",
        "\n",
        "# 5Ô∏è‚É£ Combine only if data exists\n",
        "if all_data:\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    print(\"‚úÖ Combined shape:\", combined_df.shape)\n",
        "else:\n",
        "    combined_df = pd.DataFrame()\n",
        "    print(\"‚ö†Ô∏è No valid data found in any file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill all null values with 0 BEFORE deduplication\n",
        "combined_df = combined_df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDOeLpBG1E1Y"
      },
      "outputs": [],
      "source": [
        "# Rank by data_version (higher = latest)\n",
        "combined_df[\"rank\"] = combined_df.groupby(\n",
        "    [\"Product Title\", \"PO No\", \"GRN No\", \"Invoice No\"]\n",
        ")[\"data_version\"].rank(method=\"first\", ascending=False)\n",
        "\n",
        "# Keep only top-ranked rows\n",
        "clean_df = combined_df[combined_df['rank'] == 1].drop(columns=['rank'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6CFua161IZL",
        "outputId": "369c1282-3319-40f3-f2cd-661d903d2207"
      },
      "outputs": [],
      "source": [
        "clean_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6JncNL_1b_E"
      },
      "outputs": [],
      "source": [
        "clean_df = clean_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUl1jRkE1kdm"
      },
      "outputs": [],
      "source": [
        "numeric_cols = [\n",
        "    \"PO Product Price\",\n",
        "    \"PO Product Discount Amount\",\n",
        "    \"PO Discount Amount\",\n",
        "    \"PO Product Tax\",\n",
        "    \"PO Product Cess\",\n",
        "    \"PO Product Subtotal\",\n",
        "    \"PO Product Tax Amount\",\n",
        "    \"PO TCS\",\n",
        "    \"PO Additional Charges Amount\",\n",
        "    \"PO Delivery Charges\",\n",
        "    \"PO Delivery Charges Tax\",\n",
        "    \"PO Subtotal Amount\",\n",
        "    \"PO Ordered Qty\",\n",
        "    \"PO Qty Confirmed\",\n",
        "    \"Qty Invoiced\",\n",
        "    \"Qty Delivered\",\n",
        "    \"Qty Received\",\n",
        "    \"PO Product Confirmed Total\",\n",
        "    \"Total Amt Diff\",\n",
        "]\n",
        "for col in numeric_cols:\n",
        "    if col in clean_df.columns:\n",
        "        clean_df[col] = pd.to_numeric(clean_df[col], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DIRECTLY USE clean_df - no need to save/read CSV\n",
        "df = clean_df  # Just assign it directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NafR2fv5WDJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load your CSV\n",
        "# df = pd.read_csv(\"/content/cleaned_item_wise_grn.csv\")\n",
        "\n",
        "# Clean up column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Replace NaN with None for JSON\n",
        "df = df.where(pd.notnull(df), None)\n",
        "\n",
        "# Build GRN-wise grouped structure\n",
        "final_data = []\n",
        "\n",
        "grouped = df.groupby([\"GRN No\", \"PO No\"])\n",
        "\n",
        "for (grn_no, po_no), group in grouped:\n",
        "    first_row = group.iloc[0]\n",
        "\n",
        "    record = {\n",
        "        \"grn_number\": str(grn_no) if grn_no is not None else None,  # Ensure string\n",
        "        \"purchase_order_id\": str(po_no) if po_no is not None else None,  # Ensure string\n",
        "        \"vendor_id\": (\n",
        "            str(first_row.get(\"Seller Business Name\"))\n",
        "            if first_row.get(\"Seller Business Name\") is not None\n",
        "            else None\n",
        "        ),  # Ensure string\n",
        "        \"invoice_id\": (\n",
        "            str(first_row.get(\"Invoice No\"))\n",
        "            if first_row.get(\"Invoice No\") is not None\n",
        "            else None\n",
        "        ),  # Ensure string\n",
        "        \"date_issued\": first_row.get(\"PO Creation Date\"),  # Keep as is (date string)\n",
        "        \"delivery_date\": (\n",
        "            str(first_row.get(\"Delivery Date\"))\n",
        "            if first_row.get(\"Delivery Date\") is not None\n",
        "            else None\n",
        "        ),  # Ensure string\n",
        "        \"item_list\": [],\n",
        "    }\n",
        "\n",
        "    # Loop over each item in that GRN\n",
        "    for idx, row in group.iterrows():\n",
        "        item = {\n",
        "            \"item_sequence\": (\n",
        "                int(row.get(\"S. No.\")) if pd.notna(row.get(\"S. No.\")) else None\n",
        "            ),  # Number\n",
        "            \"item_description\": (\n",
        "                str(row.get(\"Product Title\")) if row.get(\"Product Title\") is not None else None\n",
        "            ),  # String\n",
        "            \"hsn_code\": (\n",
        "                str(row.get(\"HSN No.\")) if row.get(\"HSN No.\") is not None else None\n",
        "            ),  # String\n",
        "            \"quantity\": (\n",
        "                float(row.get(\"PO Ordered Qty\"))\n",
        "                if pd.notna(row.get(\"PO Ordered Qty\"))\n",
        "                else 0\n",
        "            ),  # Number\n",
        "            \"unit_of_measurement\": (\n",
        "                str(row.get(\"UOM\")) if row.get(\"UOM\") is not None else None\n",
        "            ),  # String\n",
        "            \"rate\": (\n",
        "                float(row.get(\"PO Product Price\")) if pd.notna(row.get(\"PO Product Price\")) else 0\n",
        "            ),  # Number\n",
        "            \"cgst_rate\": (\n",
        "                float(row.get(\"CGST Tax\")) if pd.notna(row.get(\"CGST Tax\")) else 0\n",
        "            ),  # Number\n",
        "            \"cgst_amount\": (\n",
        "                float(row.get(\"CGST Tax Amount\"))\n",
        "                if pd.notna(row.get(\"CGST Tax Amount\"))\n",
        "                else 0\n",
        "            ),  # Number\n",
        "            \"sgst_rate\": (\n",
        "                float(row.get(\"SGST Tax\")) if pd.notna(row.get(\"SGST Tax\")) else 0\n",
        "            ),  # Number\n",
        "            \"sgst_amount\": (\n",
        "                float(row.get(\"SGST Tax Amount\"))\n",
        "                if pd.notna(row.get(\"SGST Tax Amount\"))\n",
        "                else 0\n",
        "            ),  # Number\n",
        "            \"igst_rate\": (\n",
        "                float(row.get(\"IGST Tax\")) if pd.notna(row.get(\"IGST Tax\")) else 0\n",
        "            ),  # Number\n",
        "            \"igst_amount\": (\n",
        "                float(row.get(\"IGST Tax Amount\"))\n",
        "                if pd.notna(row.get(\"IGST Tax Amount\"))\n",
        "                else 0\n",
        "            ),  # Number\n",
        "            \"cess_rate\": 0,  # Number\n",
        "            \"cess_amount\": (\n",
        "                float(row.get(\"PO Product Cess\")) if pd.notna(row.get(\"PO Product Cess\")) else 0\n",
        "            ),  # Number\n",
        "            \"item_total_before_tax\": (\n",
        "                float(row.get(\"PO Product Subtotal\")) if pd.notna(row.get(\"PO Product Subtotal\")) else 0\n",
        "            ),  # Number\n",
        "            \"total_tax_amount\": (\n",
        "                float(row.get(\"PO Product Tax\")) if pd.notna(row.get(\"PO Product Tax\")) else 0\n",
        "            ),  # Number\n",
        "            \"item_total_amount\": (\n",
        "                float(row.get(\"PO Product Confirmed Total\")) if pd.notna(row.get(\"PO Product Confirmed Total\")) else 0\n",
        "            ),  # Number\n",
        "        }\n",
        "        record[\"item_list\"].append(item)\n",
        "\n",
        "    # Add GRN-level totals - these will be numbers (float)\n",
        "    record[\"total_amount_without_tax\"] = (\n",
        "        float(group[\"PO Product Subtotal\"].sum()) if \"PO Product Subtotal\" in group.columns else 0.0\n",
        "    )\n",
        "    record[\"total_amount\"] = (\n",
        "        float(group[\"PO Product Confirmed Total\"].sum()) if \"PO Product Confirmed Total\" in group.columns else 0.0\n",
        "    )\n",
        "    record[\"total_gst\"] = (\n",
        "        float(group[\"PO Product Tax\"].sum()) if \"PO Product Tax\" in group.columns else 0.0\n",
        "    )\n",
        "    record[\"total_cgst\"] = (\n",
        "        float(group[\"CGST Tax Amount\"].sum())\n",
        "        if \"CGST Tax Amount\" in group.columns\n",
        "        else 0.0\n",
        "    )\n",
        "    record[\"total_sgst\"] = (\n",
        "        float(group[\"SGST Tax Amount\"].sum())\n",
        "        if \"SGST Tax Amount\" in group.columns\n",
        "        else 0.0\n",
        "    )\n",
        "    record[\"total_igst\"] = (\n",
        "        float(group[\"IGST Tax Amount\"].sum())\n",
        "        if \"IGST Tax Amount\" in group.columns\n",
        "        else 0.0\n",
        "    )\n",
        "    record[\"freight_charges\"] = (\n",
        "        float(group[\"PO Delivery Charges\"].sum())\n",
        "        if \"PO Delivery Charges\" in group.columns\n",
        "        else 0.0\n",
        "    )\n",
        "    record[\"notes\"] = (\n",
        "        str(first_row.get(\"Remarks\")) if first_row.get(\"Remarks\") is not None else None\n",
        "    )  # String\n",
        "    record[\"spoc_email\"] = None  # String (not in CSV)\n",
        "    record[\"spoc_phone\"] = None  # String (not in CSV)\n",
        "\n",
        "    final_data.append(record)\n",
        "\n",
        "# Build final JSON\n",
        "final_json = {\"data\": final_data}\n",
        "\n",
        "# Generate timestamp\n",
        "current_datetime = datetime.now()\n",
        "timestamp = current_datetime.strftime(\"%Y%m%d_%H%M%S\")  # Format: 20251111_143025\n",
        "\n",
        "# Create filename with timestamp\n",
        "output_filename = f\"po_data_{timestamp}.json\"\n",
        "\n",
        "# Save output JSON with timestamp\n",
        "with open(output_filename, \"w\") as f:\n",
        "    json.dump(final_json, f, indent=2)\n",
        "\n",
        "print(f\"JSON file saved: {output_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Upload to S3\n",
        "# -----------------------------\n",
        "\n",
        "po_output_path = f\"{seeding_po_path}/{output_filename}\"  # Path in S3\n",
        "\n",
        "# Upload file\n",
        "s3.upload_file(output_filename, bucket_name, po_output_path)\n",
        "\n",
        "print(f\"Purchase Order File uploaded to {po_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# API Config (replace with your values)\n",
        "API_BASE_URL = \"http://127.0.0.1:8005\"  # Local FastAPI URL (or ngrok/public URL if remote)\n",
        "ENDPOINT = f\"{API_BASE_URL}/api/v1/documents/create\"\n",
        "CLIENT_ID = \"1015aca0-646c-4815-9f8c-44c4843d35e2\"  # e.g., \"123e4567-e89b-12d3-a456-426614174000\" (from your DB)\n",
        "COLLECTION_NAME = \"purchase_order\"  # Your MongoDB collection name\n",
        "CREATED_BY = \"user ID\"  # e.g., \"987fcdeb-51a2-34d5-c678-9abcdef012345\" (user ID)\n",
        "\n",
        "\n",
        "# Payload (uses final_json from previous cell)\n",
        "payload = {\n",
        "    \"client_id\": CLIENT_ID,\n",
        "    \"collection_name\": COLLECTION_NAME,\n",
        "    \"data\": final_data,  # Your generated {\"data\": [...]} \n",
        "    \"created_by\": CREATED_BY\n",
        "}\n",
        "\n",
        "# Headers for auth\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# Send POST\n",
        "response = requests.post(ENDPOINT, json=payload, headers=headers)\n",
        "\n",
        "# Results\n",
        "if response.status_code == 201:\n",
        "    print(\"‚úÖ Success! GRN documents created in MongoDB.\")\n",
        "    print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
        "else:\n",
        "    print(f\"‚ùå Error {response.status_code}: {response.text}\")\n",
        "\n",
        "# Save response\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "with open(f\"api_response_{timestamp}.json\", \"w\") as f:\n",
        "    json.dump(response.json(), f, indent=2)\n",
        "print(f\"Response saved: api_response_{timestamp}.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bzb05a2q_trC"
      },
      "outputs": [],
      "source": [
        "\n",
        "moved_count = 0\n",
        "\n",
        "for source_key in csv_files:\n",
        "    try:\n",
        "        filename = source_key.split('/')[-1]\n",
        "        destination_key = f\"{processed}{filename}\"\n",
        "\n",
        "        # Copy to processed folder\n",
        "        s3.copy_object(\n",
        "            CopySource={'Bucket': bucket_name, 'Key': source_key},\n",
        "            Bucket=bucket_name,\n",
        "            Key=destination_key\n",
        "        )\n",
        "\n",
        "        # Delete from source\n",
        "        s3.delete_object(Bucket=bucket_name, Key=source_key)\n",
        "\n",
        "        moved_count += 1\n",
        "        print(f\"‚úÖ {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to move {filename}: {str(e)}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úÖ Successfully moved {moved_count}/{len(csv_files)} files\")\n",
        "print(f\"üìÅ Location: s3://{bucket_name}/{processed}\")\n",
        "print(f\"{'='*60}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
